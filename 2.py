# train_braille_sentence_model.py
import os
import cv2
import numpy as np
import pandas as pd
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
# train_braille_sentence_model.py (à¤¯à¤¾ 2.py) à¤•à¥‡ à¤¶à¥€à¤°à¥à¤· à¤ªà¤°


# ... (à¤¬à¤¾à¤•à¥€ à¤•à¥‹à¤¡) ...
# ---------------- CONFIG ----------------
DATA_DIR = "synthetic_sentences"
CSV_FILE = os.path.join(DATA_DIR, "labels.csv")
IMG_SIZE = (32,32)
MAX_SENTENCE_LEN = 8 # à¤…à¤§à¤¿à¤•à¤¤à¤® 8 à¤…à¤•à¥à¤·à¤° à¤ªà¥à¤°à¤¤à¤¿ à¤µà¤¾à¤•à¥à¤¯
BATCH_SIZE = 32
EPOCHS = 40 # à¤¸à¤Ÿà¥€à¤•à¤¤à¤¾ à¤•à¥‡ à¤²à¤¿à¤ Epochs à¤¬à¤¢à¤¼à¤¾à¤¯à¤¾ à¤—à¤¯à¤¾
MODEL_SAVE = "braille_sentence_model.h5"

# ---------------- Load Dataset ----------------
df = pd.read_csv(CSV_FILE)
sentences = df['sentence_text'].values
image_files = df['image_name'].values

X = []
y = []

for img_file, sent in zip(image_files, sentences):
    # ðŸŸ¢ 1. à¤‡à¤®à¥‡à¤œ à¤•à¥‹ à¤—à¥à¤°à¥‡à¤¸à¥à¤•à¥‡à¤² (1-à¤šà¥ˆà¤¨à¤²) à¤®à¥‡à¤‚ à¤²à¥‹à¤¡ à¤•à¤°à¥‡à¤‚
    img = cv2.imread(os.path.join(DATA_DIR, img_file), cv2.IMREAD_GRAYSCALE) 
    
    letter_width = img.shape[1] // len(sent)
    letters_imgs = []
    
    for i in range(len(sent)):
        letter_img = img[:, i*letter_width:(i+1)*letter_width]
        letter_img = cv2.resize(letter_img, IMG_SIZE)
        
        # Normalization
        letter_img = letter_img.astype("float32") / 255.0
        
        # ðŸŸ¢ 2. 1-à¤šà¥ˆà¤¨à¤² à¤‡à¤¨à¤ªà¥à¤Ÿ à¤¶à¥‡à¤ª à¤•à¥‡ à¤²à¤¿à¤ à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤•à¤°à¥‡à¤‚ (32, 32) -> (32, 32, 1)
        letter_img = np.expand_dims(letter_img, axis=-1) 
        letters_imgs.append(letter_img)
    
    # Pad to MAX_SENTENCE_LEN
    while len(letters_imgs) < MAX_SENTENCE_LEN:
        # ðŸŸ¢ 3. 1-à¤šà¥ˆà¤¨à¤² à¤¶à¥‚à¤¨à¥à¤¯ à¤ªà¥ˆà¤¡à¤¿à¤‚à¤—
        letters_imgs.append(np.zeros((IMG_SIZE[0], IMG_SIZE[1], 1), dtype=np.float32)) 
    
    X.append(letters_imgs)
    y.append(sent.ljust(MAX_SENTENCE_LEN)) # à¤²à¥‡à¤¬à¤² à¤•à¥‹ à¤­à¥€ à¤ªà¥ˆà¤¡ à¤•à¤°à¥‡à¤‚

X = np.array(X, dtype=np.float32) 
print("[INFO] X shape (N, TimeSteps, H, W, Channels):", X.shape)

# Encode characters (26 à¤…à¤•à¥à¤·à¤° + 1 à¤¸à¥à¤ªà¥‡à¤¸)
chars = list("ABCDEFGHIJKLMNOPQRSTUVWXYZ ") 
encoder = LabelEncoder()
encoder.fit(chars)

y_encoded = np.zeros((len(y), MAX_SENTENCE_LEN, len(chars)), dtype=np.float32)
for i, sent in enumerate(y):
    for j, c in enumerate(sent):
        if c in encoder.classes_:
            y_encoded[i,j] = to_categorical(encoder.transform([c])[0], num_classes=len(chars))

# Train/val split
X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

# ---------------- Build Model (CNN-LSTM Sequence) ----------------
# ðŸŸ¢ 4. à¤‡à¤¨à¤ªà¥à¤Ÿ à¤¶à¥‡à¤ª à¤•à¥‹ 1 à¤šà¥ˆà¤¨à¤² à¤ªà¤° à¤¸à¥‡à¤Ÿ à¤•à¤°à¥‡à¤‚: (MAX_SENTENCE_LEN, 32, 32, 1)
input_layer = Input(shape=(MAX_SENTENCE_LEN, IMG_SIZE[0], IMG_SIZE[1], 1)) 

# 1. CNN Features Extraction (TimeDistributed à¤•à¥‡ à¤¸à¤¾à¤¥)
x = TimeDistributed(Conv2D(32, (3,3), activation='relu', padding='same'))(input_layer)
x = TimeDistributed(MaxPooling2D(2,2))(x)
x = TimeDistributed(Conv2D(64, (3,3), activation='relu', padding='same'))(x)
x = TimeDistributed(MaxPooling2D(2,2))(x)
x = TimeDistributed(Flatten())(x)

# 2. LSTM Sequence Modeling
x = LSTM(128, return_sequences=True)(x) # return_sequences=True à¤†à¤µà¤¶à¥à¤¯à¤• à¤¹à¥ˆ
x = Dropout(0.5)(x)

# 3. Output (TimeDistributed Dense)
x = TimeDistributed(Dense(len(chars), activation='softmax'))(x)

model = Model(inputs=input_layer, outputs=x)
model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# ---------------- Train ----------------
print(f"\n[INFO] Starting training for {EPOCHS} epochs...")
history = model.fit(X_train, y_train, validation_data=(X_val, y_val),
                    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)

model.save(MODEL_SAVE)
print(f"[DONE] Model saved as {MODEL_SAVE}")